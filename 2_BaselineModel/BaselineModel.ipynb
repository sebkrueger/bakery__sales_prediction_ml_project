{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook implement a baseline model in linear regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and prepare dataset\n",
    "Load the dataset out of .pkl file we preapared ind file \"DataPreparation.ipynb\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all needed libs\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# read training data into datadframe\n",
    "train_set = pd.read_pickle('../train_val_test_data/train_set.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try the first version of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 Umsatz   R-squared:                       0.696\n",
      "Model:                            OLS   Adj. R-squared:                  0.695\n",
      "Method:                 Least Squares   F-statistic:                     2443.\n",
      "Date:                Sun, 02 Jun 2024   Prob (F-statistic):               0.00\n",
      "Time:                        16:01:06   Log-Likelihood:                -43608.\n",
      "No. Observations:                7493   AIC:                         8.723e+04\n",
      "Df Residuals:                    7485   BIC:                         8.729e+04\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "Intercept                 59.9359      2.822     21.238      0.000      54.404      65.468\n",
      "C(Warengruppe)[T.2.0]    289.2590      3.017     95.875      0.000     283.345     295.173\n",
      "C(Warengruppe)[T.3.0]     42.8076      3.017     14.189      0.000      36.893      48.722\n",
      "C(Warengruppe)[T.4.0]    -32.8345      3.045    -10.782      0.000     -38.804     -26.865\n",
      "C(Warengruppe)[T.5.0]    159.5546      3.017     52.884      0.000     153.640     165.469\n",
      "C(Warengruppe)[T.6.0]    -27.9233      5.777     -4.833      0.000     -39.249     -16.598\n",
      "Temperatur                 5.0166      0.151     33.232      0.000       4.721       5.313\n",
      "monthly_mean_temp_diff    -4.6650      0.346    -13.477      0.000      -5.344      -3.986\n",
      "==============================================================================\n",
      "Omnibus:                     7558.268   Durbin-Watson:                   1.539\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1514776.641\n",
      "Skew:                           4.497   Prob(JB):                         0.00\n",
      "Kurtosis:                      72.072   Cond. No.                         95.9\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# import all needed libs (if needed pip install)\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "mod = smf.ols('Umsatz ~ Temperatur + monthly_mean_temp_diff + C(Warengruppe)', data=train_set).fit()\n",
    "\n",
    "print(mod.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation results\n",
      "Mean Squared Error: 5538.721369179292\n",
      "R^2 Score: 0.6726461606826961\n"
     ]
    }
   ],
   "source": [
    "# read validation data into datadframe\n",
    "validation_set = pd.read_pickle('../train_val_test_data/validation_set.pkl')\n",
    "\n",
    "# Remove rows with NaN values in 'Umsatz' from the validation_set\n",
    "# Potential TO-DO: look why we have this 8 rows of NaN data?\n",
    "validation_set = validation_set.dropna(subset=['Umsatz'])\n",
    "\n",
    "# Make predictions on the validation data\n",
    "validation_set['Umsatz_predictions'] = mod.predict(validation_set)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mse = mean_squared_error(validation_set['Umsatz'], validation_set['Umsatz_predictions'])\n",
    "r2 = r2_score(validation_set['Umsatz'], validation_set['Umsatz_predictions'])\n",
    "\n",
    "print(\"Validation results\")\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R^2 Score: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions based on model above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK : DataFrame has exact 1830 Entries!\n"
     ]
    }
   ],
   "source": [
    "# load testset\n",
    "test_set = pd.read_pickle('../train_val_test_data/test_set.pkl')\n",
    "\n",
    "# calculate predictions for later upload \n",
    "test_set['Umsatz'] = mod.predict(test_set)\n",
    "\n",
    "test_set.head()\n",
    "\n",
    "# reduce to id and Umsatz columns \n",
    "submission_set = test_set[['id','Umsatz']]\n",
    "\n",
    "# Check if the count of dataset is correct for kaggle upload\n",
    "if submission_set.shape[0] == 1830:\n",
    "    print(\"OK : DataFrame has exact 1830 Entries!\")\n",
    "else:\n",
    "    print(f\"ERROR Dataframe has wrong number of {df.shape[0]} Entries!\")\n",
    "\n",
    "# store the submission data\n",
    "submission_set.to_csv('../prediction_data/submission.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
